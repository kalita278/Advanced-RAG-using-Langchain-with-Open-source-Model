# Advanced-RAG system-using-Langchain-with-Open-source-Model
# üë®‚ÄçüíªBuilding a RAG System

<p align="center">
    <img width="500" src="https://github.com/HannahIgboke/Building-a-RAG-System/blob/main/RAG.png" alt="RAG">
</p>


As we know that LLMs like Gemini, Gpt, Llama lack the company specific information. But this latest information is available via PDFs, Text Files, specific websites etc... Now if we can connect our LLM with these sources, we can build a much better application.


Using LangChain framework, I built a  Retrieval Augmented Generation (RAG) system that can utilize the power of LLM like Llama, Gemini 1.5 Pro to answer questions on specific pdfs, websites, wikipedia, arXiv etc. In this process, external data(i.e. the Leave No Context Behind Paper) is retrieved and then passed to the LLM during the generation step.


# üõ† Tech stack
- Langchain
- ChromaDB, FAISS, ObjectBox
- Streamlit

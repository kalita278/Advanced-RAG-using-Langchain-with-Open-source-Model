{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'NLP-2_Problem Statement-1.pdf', 'page': 0}, page_content=' \\n \\n©Great  Learning.  Proprietary  content.  All Rights  Reserved.  Unauthorised  use or distribution  prohibited  MODULE  \\nPROJECT  AIML   \\n'),\n",
       " Document(metadata={'source': 'NLP-2_Problem Statement-1.pdf', 'page': 1}, page_content=' \\n \\n• DOMAIN : Digital  content  and  entertainment  industry  \\n• CONTEXT : The  objective  of this  project  is to build  a text  classification  model  that  analyses  the customer\\'s  sentiments  \\nbased  on their  reviews  in the IMDB  database.  The  model  uses  a complex  deep  learning  model  to build  an embedding  layer  \\nfollowed  by a classification  algorithm  to analyse  the sentiment  of the customers.  \\n• DATA  DESCRIPTION : The  Dataset  of 50,000  movie  reviews  from  IMDB,  labelled  by sentiment  (positive/negative).  Reviews  \\nhave been  preprocessed,  and  each  review  is encoded  as a sequence  of word  indexes  (integers).  For convenience,  the \\nwords  are indexed  by their  frequency  in the dataset,  meaning  the for that  has index  1 is the most  frequent  word.  Use  the \\nfirst  20 words  from  each review  to speed  up training,  using  a max  vocabulary  size  of 10,000.  As a convention,  \"0\" does  \\nnot stand  for a specific  word,  but instead  is used  to encode  any  unknown  word.  \\n• PROJECT  OBJECTIVE : To Build  a sequential  NLP  classifier  which  can  use input  text  parameters  to determine  the customer  \\nsentiments.  \\nSteps  and  tasks : [ Total  Score:  30 Marks]  \\n1. Import  and analyse  the data  set. [5 Marks]   \\nHint:  - Use `imdb.load_data()`  method  \\n        -  Get train  and test set \\n          - Take  10000  most  frequent  words  \\n2. Perform  relevant  sequence  adding  on the data.  [5 Marks]  \\n3. Perform  following  data  analysis:  [5 Marks]  \\n• Print  shape  of features  and labels  \\n• Print  value  of any one feature  and it\\'s label  \\n4. Decode  the feature  value  to get original  sentence  [5 Marks]  \\n5. Design,  train,  tune and test a sequential  model.  [5 Marks]  \\nHint : The aim here  Is to import  the text,  process  it such  a way  that  it can be taken  as an inout  to the ML/NN  classifiers.  Be analytical  \\nand experimental  here  in trying  new  approaches  to design  the best  model.  \\n6. Use the designed  model  to print  the prediction  on any one sample.  [5 Marks]  \\n \\nPlease  Note:  \\n Intentionally  limited  questions/instructions  are provided  so that  learners  can explore  more  and perform  more  research  \\nsince  learners  are comfortable  with  all the concepts  and implementation.  \\n \\n \\n \\n \\n©Great  Learning.  Proprietary  content.  All Rights  Reserved.  Unauthorised  use or distribution  prohibited  TOTAL  \\nSCORE  60  Sequential  NLP  AIML  MODULE  PROJECT  \\n     Part A - 30 Marks  '),\n",
       " Document(metadata={'source': 'NLP-2_Problem Statement-1.pdf', 'page': 2}, page_content=' \\n  \\n• DOMAIN : Social  media  analytics  \\n• CONTEXT : Past  studies  in Sarcasm  Detection  mostly  make  use of Twitter  datasets  collected  using  hashtag  based  supervision  \\nbut such  datasets  are noisy  in terms  of labels  and  language.  Furthermore,  many  tweets  are replies  to other  tweets  and  \\ndetecting  sarcasm  in these  requires  the availability  of contextual  tweets.In  this  hands -on project,  the goal  is to build  a model  \\nto detect  whether  a sentence  is sarcastic  or not,  using  Bidirectional  LSTMs.  \\n• DATA  DESCRIPTION :  \\nThe  dataset  is collected  from  two  news  websites,  theonion.com  and  huffingtonpost.com .  \\nThis  new  dataset  has the following  advantages  over  the existing  Twitter  datasets:  \\nSince  news  headlines  are written  by professionals  in a formal  manner,  there  are no spelling  mistakes  and informal  usage.  This  reduces  \\nthe sparsity  and also  increases  the chance  of finding  pre-trained  embeddings.  \\nFurthermore,  since  the sole  purpose  of TheOnion  is to publish  sarcastic  news,  we get high -quality  labels  with  much  less noise  as \\ncompared  to Twitter  datasets.  \\nUnlike  tweets  that  reply  to other  tweets,  the news  headlines  obtained  are self-contained.  This  would  help  us in teasing  apart  the real  \\nsarcastic  elements  \\nContent : Each  record  consists  of three  attributes:  \\nis_sarcastic:  1 if the record  is sarcastic  otherwise  0 \\nheadline:  the headline  of the news  article  \\narticle_link:  link to the original  news  article.  Useful  in collecting  supplementary  data  \\n     Reference:  https://github.com/rishabhmisra/News -Headlines -Dataset -For-Sarcasm -Detection  \\n \\n• PROJECT  OBJECTIVE : Build  a sequential  NLP  classifier  which  can  use input  text  parameters  to determine  the customer  \\nsentiments.  \\nSteps  and  tasks : [ Total  Score:  30 Marks]  \\n1. Read  and explore  the data  [3 Marks]  \\n2. Retain  relevant  columns  [3 Marks]  \\n3. Get length  of each  sentence  [3 Marks]  \\n4. Define  parameters  [3 Marks]  \\n5. Get indices  for words  [3 Marks]  \\n6. Create  features  and labels  [3 Marks]  \\n7. Get vocab ulary  size  [3 Marks]  \\n8. Create  a weight  matrix  using  GloVe  embeddings  [3 Marks]  \\n9. Define  and compile  a LSTM  model.  [3 Marks]  \\n      Hint : Be analytical  and experimental  here  in trying  new  approaches  to design  the best  model.  \\n10.  Fit the model  and check  the validation  accuracy  [3 Marks]  \\n \\n \\nPlease  Note:  \\nIntentionally  limited  questions/instructions  are provided  so that  learners  can explore  more  and perform  more  research  since  \\nlearners  are comfortable  with  all the concepts  and implementation.  \\n \\n \\n \\n \\n©Great  Learning.  Proprietary  content.  All Rights  Reserved.  Unauthorised  use or distribution  prohibited  AIML  MODULE  PROJECT  \\n     Part B - 30 Marks  ')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading pdf file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('NLP-2_Problem Statement-1.pdf')\n",
    "doc = loader.load()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "split_doc = splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mrinal Kalita\\Python Projects\\RAG using langchain\\myvenv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "#Create vector datbase\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(split_doc,HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Ollama model\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model='llama2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content=\"hi! I'm bob\"),\n",
       " AIMessage(content='hi!'),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    ('system',\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer.\n",
    "Please give accurate and precise answer.\n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\"),\n",
    "MessagesPlaceholder(variable_name='messages')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction\n",
    "## Create Stuff Docment Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer) |create_stuff_documents_chain(llm,prompt)\n",
    "#document_chain1 = RunnablePassthrough.assign(messages=itemgetter(\"messages\") | document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retriever\n",
    "db_retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retruval chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(db_retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"messages\": messages,\n",
    "                                 \"input\":\"How many steps are there in the project?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, there are 8 steps in the project. They are:\\n\\n1. Import and analyze the data set.\\n2. Perform relevant sequence adding on the data.\\n3. Print the shape of features and labels.\\n4. Print the value of any one feature and its label.\\n5. Decode the feature value to get the original sentence.\\n6. Design, train, tune, and test a sequential model.\\n7. Get length of each sentence.\\n8. Define parameters.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "history_retriever = create_history_aware_retriever(llm,db_retriever,contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Managing state chat history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_message_history(session_id :str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    return store[session_id]\n",
    "\n",
    "conv_rag_chain = RunnableWithMessageHistory(rag_chain,get_message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_rag_chain.invoke({\"messages\": messages,\n",
    "    'input':\"How many steps are there in the project\"},config={\n",
    "        \"configurable\": {\"session_id\": \"ad12\"}\n",
    "    },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, there are a total of 8 steps in the project. These steps are:\\n\\n1. Import and analyse the data set.\\n2. Perform relevant sequence adding on the data.\\n3. Print the shape of features and labels.\\n4. Print the value of any one feature and its label.\\n5. Decode the feature value to get the original sentence.\\n6. Design, train, tune, and test a sequential model.\\n7. Get length of each sentence.\\n8. Create features and labels.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_rag_chain.invoke({\"messages\": messages,\n",
    "    'input':\"What is the objective of this\"},config={\n",
    "        \"configurable\": {\"session_id\": \"ad12\"}},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The objective of the system is to build a sequential NLP classifier that can use input text parameters to determine customer sentiments. Specifically, the tasks and steps involved in the project are:\\n\\n1. Import and analyze the data set: 5 marks\\n\\t* Use `imdb.load_data()` method\\n\\t* Get train and test sets\\n\\t* Take the top 10000 most frequent words\\n2. Perform relevant sequence adding on the data: 5 marks\\n\\t* Add sequential data to the input text parameters\\n3. Perform following data analysis: 5 marks\\n\\t* Print shape of features and labels\\n\\t* Print value of any one feature and its label\\n4. Decode the feature value to get original sentence: 5 marks\\n\\t* Use GloVe embeddings to decode the feature values\\n5. Design, train, tune, and test a sequential model: 5 marks\\n\\t* Use LSTM model with GloVe embeddings as input features\\n\\t* Train the model using the data set\\n\\t* Tune the model by adjusting the hyperparameters\\n\\t* Test the model on a new dataset to evaluate its performance\\n\\nThe total score for this project is 60 marks.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_rag_chain.invoke({\"messages\": messages,\n",
    "    'input':\"What is the objective of this\"},config={\n",
    "        \"configurable\": {\"session_id\": \"ad15\"}},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The objective of the project is to build a sequential NLP classifier that can use input text parameters to determine customer sentiments. The steps and tasks involved in the project are:\\n\\n1. Import and analyze the data set. (5 marks)\\n2. Perform relevant sequence adding on the data. (5 marks)\\n3. Perform data analysis, including printing the shape of features and labels, and printing the value of any one feature and its label. (5 marks)\\n4. Decode the feature value to get the original sentence. (5 marks)\\n5. Design, train, tune, and test a sequential model. (5 marks)\\n\\nThe project also provides a reference link for collecting supplementary data. (1 mark)\\n\\nTotal score: 30 marks'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
